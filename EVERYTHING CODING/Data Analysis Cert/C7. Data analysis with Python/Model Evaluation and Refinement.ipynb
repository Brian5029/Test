{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "373040e9",
   "metadata": {},
   "source": [
    "estimating parameters (creating a best fit line) is called training the algorithm\n",
    "\n",
    "if the training data's residual is significantly smaller than testing data's residual, it is over fit (meaning training set of line has high variance)\n",
    "\n",
    "ridge regression will slowly tilt the training line to `Generalize` more. In other words, Ridge regression will make the line slightly worse fit but in return provide bettern prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c28826",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990c89cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DA0101EN-SkillsNetwork/labs/Data%20files/module_5_auto.csv'\n",
    "df = pd.read_csv(path)\n",
    "df.to_csv('module_5_auto.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9434374a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df._get_numeric_data()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba65778",
   "metadata": {},
   "source": [
    "# Training and Testing \n",
    "Before creating a model, its an important step to split your data into training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487c03e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = df['price']\n",
    "y_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6975ec4b",
   "metadata": {},
   "source": [
    "We will drop `data` in the dataframe x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33212041",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data=df.drop('price',axis=1)\n",
    "x_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654988fe",
   "metadata": {},
   "source": [
    "We now randomly split the data into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a39a4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2937916a",
   "metadata": {},
   "source": [
    "`test_size` paramaeter sets the proportion of data in this testing, testing set is 10% of the total dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195922c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.10, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f656ba96",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"number of test samples :\", x_test.shape[0])\n",
    "print(\"number of training samples:\",x_train.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b50f926",
   "metadata": {},
   "source": [
    "Lets use these datas and fit into our LinearRegression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a123bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56713758",
   "metadata": {},
   "outputs": [],
   "source": [
    "lre=LinearRegression()\n",
    "lre.fit(x_train[['horsepower']], y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600dcb57",
   "metadata": {},
   "source": [
    "We can see R^2 value is much smaller on testing data compared to training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fa8d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "lre.score(x_test[['horsepower']], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e764cc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lre.score(x_train[['horsepower']], y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6106ac",
   "metadata": {},
   "source": [
    "# Cross Validation Score\n",
    "Separating the datas into different folds and use one of the folds as testing data until all folds are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d866d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc913d3",
   "metadata": {},
   "source": [
    "We create an cross val score with x_data, y_data in linear regression model and the parameter 'cv' determines the number of fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325ff205",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rcross = cross_val_score(lre, x_data[['horsepower']], y_data, cv=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c8a80e",
   "metadata": {},
   "source": [
    "The default scoring is R^2. Each element in the array has the average R^2 value for the fold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4097046",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rcross"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a13c9d",
   "metadata": {},
   "source": [
    "We can also calculate the average and standarad deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d365904",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rcross.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771bf87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rcross.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbc2612",
   "metadata": {},
   "source": [
    "You can also use the function `crodd_val_predict` to predict the output of each fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5eb3997",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1580c0d",
   "metadata": {},
   "source": [
    "The function automatically splits up the dat ainto testing and training with the specified number of folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872bcbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = cross_val_predict(lre,x_data[['horsepower']], y_data,cv=4)\n",
    "yhat[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3883d613",
   "metadata": {},
   "source": [
    "# Overfitting, Underfitting and Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68427fcd",
   "metadata": {},
   "source": [
    "First, lets create Multiple Linear Regression and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992a10aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(x_train[['horsepower', 'curb-weight', 'engine-size', 'highway-mpg']], y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0664e7",
   "metadata": {},
   "source": [
    "prediction using training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43962a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_train = lr.predict(x_train[['horsepower', 'curb-weight', 'engine-size', 'highway-mpg']])\n",
    "yhat_train[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da4dcfb",
   "metadata": {},
   "source": [
    "prediction using testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2484d884",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_test = lr.predict(x_test[['horsepower', 'curb-weight', 'engine-size', 'highway-mpg']])\n",
    "yhat_test[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98dd6da2",
   "metadata": {},
   "source": [
    "### Visualizing test and training data\n",
    "- Do not have to know how these visualization functions work yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695c7643",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342cfd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DistributionPlot(RedFunction, BlueFunction, RedName, BlueName, Title):\n",
    "    width = 12\n",
    "    height = 10\n",
    "    plt.figure(figsize=(width, height))\n",
    "\n",
    "    ax1 = sns.distplot(RedFunction, hist=False, color=\"r\", label=RedName)\n",
    "    ax2 = sns.distplot(BlueFunction, hist=False, color=\"b\", label=BlueName, ax=ax1)\n",
    "\n",
    "    plt.title(Title)\n",
    "    plt.xlabel('Price (in dollars)')\n",
    "    plt.ylabel('Proportion of Cars')\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cef929",
   "metadata": {},
   "outputs": [],
   "source": [
    "Title = 'Distribution  Plot of  Predicted Value Using Training Data vs Training Data Distribution'\n",
    "DistributionPlot(y_train, yhat_train, \"Actual Values (Train)\", \"Predicted Values (Train)\", Title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7789cda9",
   "metadata": {},
   "source": [
    "Plot of predicted values using `training` data compared to actual values of the `training` data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9256dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Title='Distribution  Plot of  Predicted Value Using Test Data vs Data Distribution of Test Data'\n",
    "DistributionPlot(y_test,yhat_test,\"Actual Values (Test)\",\"Predicted Values (Test)\",Title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c24f1c",
   "metadata": {},
   "source": [
    "Plot of predicted values using `testing` data compared to actual values of the `testing` data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba621289",
   "metadata": {},
   "source": [
    "Comparing Figure 1 and 2, it is evident that distribution of figure 1 (using training set) is more accurate than figure 2 (using testing set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a259dfc9",
   "metadata": {},
   "source": [
    "Let's see if polynomial regression also exhibits a drop in the prediction accuracy when analysing the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83ae79d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda8d268",
   "metadata": {},
   "source": [
    "### Overfitting\n",
    "occurs when the model fits the noise therefore the model does not perform well since it is modelling noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2b4f492",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-9728173faf7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.45\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.45, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1160d029",
   "metadata": {},
   "source": [
    "Using degree 5 polynomial transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adc3c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = PolynomialFeatures(degree=5)\n",
    "x_train_pr = pr.fit_transform(x_train[['horsepower']])\n",
    "x_test_pr = pr.fit_transform(x_test[['horsepower']])\n",
    "pr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3596d03",
   "metadata": {},
   "source": [
    "Training Linear Regression using Splitted polynomial transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bacac78",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = LinearRegression()\n",
    "poly.fit(x_train_pr, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28debb92",
   "metadata": {},
   "source": [
    "We can see the prediction of our polynomial model using `test` data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a95040",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = poly.predict(x_test_pr)\n",
    "yhat[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8a9eb2",
   "metadata": {},
   "source": [
    "comparing `test` data prediction with actual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bc9d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Predicted values:\", yhat[0:4])\n",
    "print(\"Actual values:\", y_test[0:4].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4ff7dc",
   "metadata": {},
   "source": [
    "Using pollyplot function to display the training data nd testing data and predicted function\n",
    "- Do now have to know how these functions work yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7652d774",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, interactive, fixed, interact_manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab82cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PollyPlot(xtrain, xtest, y_train, y_test, lr,poly_transform):\n",
    "    width = 12\n",
    "    height = 10\n",
    "    plt.figure(figsize=(width, height))\n",
    "    \n",
    "    \n",
    "    #training data \n",
    "    #testing data \n",
    "    # lr:  linear regression object \n",
    "    #poly_transform:  polynomial transformation object \n",
    " \n",
    "    xmax=max([xtrain.values.max(), xtest.values.max()])\n",
    "\n",
    "    xmin=min([xtrain.values.min(), xtest.values.min()])\n",
    "\n",
    "    x=np.arange(xmin, xmax, 0.1)\n",
    "\n",
    "\n",
    "    plt.plot(xtrain, y_train, 'ro', label='Training Data')\n",
    "    plt.plot(xtest, y_test, 'go', label='Test Data')\n",
    "    plt.plot(x, lr.predict(poly_transform.fit_transform(x.reshape(-1, 1))), label='Predicted Function')\n",
    "    plt.ylim([-10000, 60000])\n",
    "    plt.ylabel('Price')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66a2319",
   "metadata": {},
   "outputs": [],
   "source": [
    "PollyPlot(x_train[['horsepower']], x_test[['horsepower']], y_train, y_test, poly,pr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca6284a",
   "metadata": {},
   "source": [
    "We see that the estimated function appears to track the data but around 200 horsepower, the function begins to diverge from the data points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b98b71",
   "metadata": {},
   "source": [
    "Checking the R^2 score of `training` data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d969d973",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly.score(x_train_pr, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d683a4",
   "metadata": {},
   "source": [
    "Checking the R^2 score of `testing` data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c475102",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly.score(x_test_pr, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5097ff",
   "metadata": {},
   "source": [
    "We see the R^2 for the training data is 0.5567 while the R^2 on the test data was -29.87.  The lower the R^2, the worse the model. A negative R^2 is a sign of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7df2e7b",
   "metadata": {},
   "source": [
    "Lets see how R^2 changes on the test data for different order of polynomials and plot the result using forloop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9753404a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rsqu_test = []\n",
    "\n",
    "order = [1, 2, 3, 4]\n",
    "for n in order:\n",
    "    pr = PolynomialFeatures(degree=n)\n",
    "    \n",
    "    x_train_pr = pr.fit_transform(x_train[['horsepower']])\n",
    "    \n",
    "    x_test_pr = pr.fit_transform(x_test[['horsepower']])    \n",
    "    \n",
    "    lr.fit(x_train_pr, y_train)\n",
    "    \n",
    "    Rsqu_test.append(lr.score(x_test_pr, y_test))\n",
    "\n",
    "plt.plot(order, Rsqu_test)\n",
    "plt.xlabel('order')\n",
    "plt.ylabel('R^2')\n",
    "plt.title('R^2 Using Test Data')\n",
    "plt.text(3, 0.75, 'Maximum R^2 ')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ce5ddb",
   "metadata": {},
   "source": [
    "We see the R^2 gradually increases until an order three polynomial is used. Then, the R^2 dramatically decreases at an order four polynomial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e5c97d",
   "metadata": {},
   "source": [
    "Dont have to know how this fucntion works yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500a48e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(order, test_data):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=test_data, random_state=0)\n",
    "    pr = PolynomialFeatures(degree=order)\n",
    "    x_train_pr = pr.fit_transform(x_train[['horsepower']])\n",
    "    x_test_pr = pr.fit_transform(x_test[['horsepower']])\n",
    "    poly = LinearRegression()\n",
    "    poly.fit(x_train_pr,y_train)\n",
    "    PollyPlot(x_train[['horsepower']], x_test[['horsepower']], y_train,y_test, poly, pr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc49ea0c",
   "metadata": {},
   "source": [
    "This function allows you to experiment with different polynomial orders and different amounts of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff1dbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(f, order=(0, 6, 1), test_data=(0.05, 0.95, 0.05))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e487f0",
   "metadata": {},
   "source": [
    "# Ridge Regression (Regularization)\n",
    "Ridge Regression uses `alpha` parameter to change the model.\n",
    "- Altering alpha will avoid overfitting\n",
    "- As alpha increase, the model becomes less sensitive to variations of independent variable (Line becomes more horizontal)\n",
    "In other words, we are shifting our model to\n",
    "- perform consistently well on both training and testing dataset\n",
    "- in return, the model performance will slightly be poorer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68418ec4",
   "metadata": {},
   "source": [
    "Let's perform a degree two polynomial transformation on our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63c284f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PolynomialFeatures' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-e5fc8582f453>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mPolynomialFeatures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdegree\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mx_train_pr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'horsepower'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'curb-weight'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'engine-size'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'highway-mpg'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'normalized-losses'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'symboling'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mx_test_pr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'horsepower'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'curb-weight'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'engine-size'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'highway-mpg'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'normalized-losses'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'symboling'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'PolynomialFeatures' is not defined"
     ]
    }
   ],
   "source": [
    "pr=PolynomialFeatures(degree=2)\n",
    "x_train_pr=pr.fit_transform(x_train[['horsepower', 'curb-weight', 'engine-size', 'highway-mpg','normalized-losses','symboling']])\n",
    "x_test_pr=pr.fit_transform(x_test[['horsepower', 'curb-weight', 'engine-size', 'highway-mpg','normalized-losses','symboling']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cfc8e0",
   "metadata": {},
   "source": [
    "Creating Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "796a59b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train_pr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-1baadaa61f42>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRidge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mRigeModel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mRidge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mRigeModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train_pr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'x_train_pr' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "RigeModel=Ridge(alpha=1)\n",
    "RigeModel.fit(x_train_pr, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5f1771",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = RigeModel.predict(x_test_pr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139a1223",
   "metadata": {},
   "source": [
    "Comparing the first five predicted samples to our test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229924dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('predicted:', yhat[0:4])\n",
    "print('test set :', y_test[0:4].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b5c761",
   "metadata": {},
   "source": [
    "# Grid Search\n",
    "The term `Alpha` is called hyperparameter and `GridSearchCV` makes the process of finding the best hyperparameter simpler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ecacb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d8fbf20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'alpha': [0.001, 0.1, 1, 10, 100, 1000, 10000, 100000, 100000]}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters1= [{'alpha': [0.001,0.1,1, 10, 100, 1000, 10000, 100000, 100000]}]\n",
    "parameters1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae25ef0",
   "metadata": {},
   "source": [
    "Creating Ridge regression object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d6e4566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RR=Ridge()\n",
    "RR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b32203b",
   "metadata": {},
   "source": [
    "Creating Ridge Grid Search object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "564802b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Grid1 = GridSearchCV(RR, parameters1,cv=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6887c0",
   "metadata": {},
   "source": [
    "Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58300bb7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-f59582f18351>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mGrid1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'horsepower'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'curb-weight'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'engine-size'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'highway-mpg'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "Grid1.fit(x_train[['horsepower', 'curb-weight', 'engine-size', 'highway-mpg']], y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d21dad",
   "metadata": {},
   "source": [
    "The object finds the best parameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e918bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "BestRR=Grid1.best_estimator_\n",
    "BestRR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0afd15",
   "metadata": {},
   "source": [
    "We can now test our model on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8da680",
   "metadata": {},
   "outputs": [],
   "source": [
    "BestRR.score(x_test[['horsepower', 'curb-weight', 'engine-size', 'highway-mpg']], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a956e52b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
